# Data Engineering Pipeline

Цей проєкт створює пайплайн для завантаження даних у Google Cloud Storage за допомогою Apache Airflow. Завданням є підготовка до курсового проєкту, де потрібно завантажити дані з API у форматі CSV і зберегти їх у Cloud Storage.

### Опис пайплайну

- **DAG** запускається за конкретною датою.
- **Завдання**:
  - Завантаження даних із API.
  - Збереження даних у бакет Cloud Storage у вигляді CSV.
- **Шлях збереження** даних у бакеті: `src1/sales/v1/рік/місяць/день/`.

### Вимоги

Для запуску проєкту потрібно встановити пакети з `requirements.txt`.
